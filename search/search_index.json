{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Project Documentation","text":""},{"location":"#drawer_1","title":"<code>drawer</code>","text":""},{"location":"#drawer.PaintApp","title":"<code>PaintApp</code>","text":"<p>A simple application for drawing digits and predicting them using a server.</p> <p>This class provides a graphical interface for users to draw digit shapes on a canvas. It includes functionalities to predict the drawn digit, clear the canvas, and handle the communication with a server for digit recognition.</p> Method and Attribute Summary <ul> <li>init: Initializes the application interface with a canvas, buttons,   and a label for displaying predictions, along with thread safety mechanisms.</li> <li>paint: Handles mouse events to draw oval shapes on the canvas.</li> <li>clear_canvas: Resets the canvas to its initial state and clears the result label.</li> <li>trigger_send_image: Starts a new thread to send the drawn image for prediction.</li> <li>send_image: Processes and sends the drawn image to a server for prediction   and updates the UI with the result.</li> </ul> Source code in <code>drawer.py</code> <pre><code>class PaintApp:\n    \"\"\"\n    A simple application for drawing digits and predicting them using a server.\n\n    This class provides a graphical interface for users to draw digit shapes\n    on a canvas. It includes functionalities to predict the drawn digit, clear\n    the canvas, and handle the communication with a server for digit recognition.\n\n    Methods:\n        __init__\n        paint\n        clear_canvas\n        trigger_send_image\n        send_image\n\n    Attributes:\n        None\n\n    Method and Attribute Summary:\n        - __init__: Initializes the application interface with a canvas, buttons,\n          and a label for displaying predictions, along with thread safety mechanisms.\n        - paint: Handles mouse events to draw oval shapes on the canvas.\n        - clear_canvas: Resets the canvas to its initial state and clears the result label.\n        - trigger_send_image: Starts a new thread to send the drawn image for prediction.\n        - send_image: Processes and sends the drawn image to a server for prediction\n          and updates the UI with the result.\n    \"\"\"\n\n    def __init__(self, root):\n        \"\"\"\n        Initializes the application interface for drawing a digit.\n\n            This method sets up the main application window, including a canvas\n            for drawing, buttons for predicting the digit and clearing the canvas,\n            and a label to display the prediction results. It also initializes an image\n            object for storing the drawn digit and sets up a lock for thread safety.\n\n            Args:\n                root: The root window or parent widget for the application interface.\n\n            Returns:\n                None\n        \"\"\"\n        self.root = root\n        self.root.title(\"Draw a Digit\")\n        self.canvas = tk.Canvas(self.root, width=WIDTH, height=HEIGHT, bg=\"white\")\n        self.canvas.pack()\n\n        self.button_frame = tk.Frame(self.root)\n        self.button_frame.pack()\n\n        self.predict_btn = tk.Button(\n            self.button_frame, text=\"Predict\", command=self.trigger_send_image\n        )\n        self.predict_btn.pack(side=tk.LEFT, padx=10)\n\n        self.clear_btn = tk.Button(\n            self.button_frame, text=\"Clear\", command=self.clear_canvas\n        )\n        self.clear_btn.pack(side=tk.LEFT)\n\n        self.result_label = tk.Label(self.root, text=\"\", font=(\"Helvetica\", 16))\n        self.result_label.pack()\n\n        self.image = Image.new(\"L\", (WIDTH, HEIGHT), \"white\")\n        self.draw = ImageDraw.Draw(self.image)\n\n        self._lock = threading.Lock()\n        self._latest_request_id = 0\n        self.last_working_index = 0\n\n        self.servers = [\n            \"http://localhost:8080/predictions/mnist\",  # TorchServe\n            \"http://localhost:8000/predict\",  # FastAPI\n        ]\n\n        self.canvas.bind(\"&lt;B1-Motion&gt;\", self.paint)\n\n    def paint(self, event):\n        \"\"\"\n        Draws an oval shape on the canvas based on mouse click coordinates.\n\n            This method is triggered by a mouse event and it creates an oval on\n            the canvas at the location where the mouse is clicked. The oval has a\n            fixed size and is filled with a black color.\n\n            Args:\n                event: The mouse event containing the x and y coordinates\n                       of the mouse click.\n\n            Returns:\n                None\n        \"\"\"\n        x1, y1 = (event.x - 8), (event.y - 8)\n        x2, y2 = (event.x + 8), (event.y + 8)\n        self.canvas.create_oval(x1, y1, x2, y2, fill=\"black\", outline=\"black\")\n        self.draw.ellipse([x1, y1, x2, y2], fill=\"black\")\n\n    def clear_canvas(self):\n        \"\"\"\n        Clears the canvas and resets its state.\n\n            This method deletes all items from the canvas and redraws a white rectangle\n            over the entire canvas area to clear it. Additionally, it resets the text\n            of the result label to an empty string.\n\n            Parameters:\n                None\n\n            Returns:\n                None\n        \"\"\"\n        self.canvas.delete(\"all\")\n        self.draw.rectangle([0, 0, WIDTH, HEIGHT], fill=\"white\")\n        self.result_label.config(text=\"\")\n\n    def trigger_send_image(self):\n        \"\"\"\n        Triggers the sending of an image in a separate thread.\n\n            This method increments the latest request ID and starts a new thread\n            to send an image using the updated request ID. The thread is set as a\n            daemon, meaning it will not prevent the program from exiting.\n\n            Parameters:\n                None\n\n            Returns:\n                None\n        \"\"\"\n        with self._lock:\n            self._latest_request_id += 1\n            request_id = self._latest_request_id\n\n        thread = threading.Thread(target=self.send_image, args=(request_id,))\n        thread.daemon = True\n        thread.start()\n\n    def send_image(self, request_id):\n        \"\"\"\n        Sends a pre-processed image to a server for prediction.\n\n            This method rescales the image to 28x28 pixels and converts it to grayscale,\n            inverts the pixel values, and encodes the image as a base64 string. It then\n            sends this encoded image to the preferred server for prediction. In case of\n            a failure to connect, it retries with a fallback server. The method updates\n            the user interface with the predicted class or an error message accordingly.\n\n            Args:\n                request_id: An identifier for the request, used to track the most\n                    recent processing request and update the label correctly.\n\n            Returns:\n                None\n        \"\"\"\n        # \u041c\u0430\u0441\u0448\u0442\u0430\u0431\u0438\u0440\u0443\u0435\u043c \u0434\u043e 28x28, \u043a\u0430\u043a MNIST\n        img = self.image.resize((28, 28)).convert(\"L\")\n\n        # \u0418\u043d\u0432\u0435\u0440\u0442\u0438\u0440\u0443\u0435\u043c (\u0431\u0435\u043b\u044b\u0439 -&gt; 0, \u0447\u0435\u0440\u043d\u044b\u0439 -&gt; 255)\n        img = Image.eval(img, lambda x: 255 - x)\n\n        # \u041e\u0442\u043f\u0440\u0430\u0432\u043b\u044f\u0435\u043c \u0432 API\n        buffer = io.BytesIO()\n        img.save(buffer, format=\"PNG\")\n        img_bytes = buffer.getvalue()\n        img_b64 = base64.b64encode(img_bytes).decode(\"utf-8\")\n        payload = {\"image_bytes\": img_b64}\n\n        def update_label(text):\n            self.root.after(0, self.result_label.config, {\"text\": text})\n\n        # Prioritize the last successful server\n        primary = self.servers[self.last_working_index]\n        fallback = self.servers[1 - self.last_working_index]\n\n        for idx, server in enumerate([primary, fallback]):\n            try:\n                response = requests.post(server, json=payload, timeout=3)\n                pred = response.json()\n                if isinstance(pred, dict):\n                    pred = pred.get(\"class_id\", pred)\n\n                with self._lock:\n                    if request_id == self._latest_request_id:\n                        self.last_working_index = self.servers.index(server)\n                        update_label(f\"Predicted: {pred}\")\n                return\n            except Exception:\n                continue\n\n        with self._lock:\n            if request_id == self._latest_request_id:\n                update_label(\"Error: all servers unreachable.\")\n</code></pre>"},{"location":"#drawer.PaintApp.__init__","title":"<code>__init__(root)</code>","text":"<p>Initializes the application interface for drawing a digit.</p> <pre><code>This method sets up the main application window, including a canvas\nfor drawing, buttons for predicting the digit and clearing the canvas,\nand a label to display the prediction results. It also initializes an image\nobject for storing the drawn digit and sets up a lock for thread safety.\n\nArgs:\n    root: The root window or parent widget for the application interface.\n\nReturns:\n    None\n</code></pre> Source code in <code>drawer.py</code> <pre><code>def __init__(self, root):\n    \"\"\"\n    Initializes the application interface for drawing a digit.\n\n        This method sets up the main application window, including a canvas\n        for drawing, buttons for predicting the digit and clearing the canvas,\n        and a label to display the prediction results. It also initializes an image\n        object for storing the drawn digit and sets up a lock for thread safety.\n\n        Args:\n            root: The root window or parent widget for the application interface.\n\n        Returns:\n            None\n    \"\"\"\n    self.root = root\n    self.root.title(\"Draw a Digit\")\n    self.canvas = tk.Canvas(self.root, width=WIDTH, height=HEIGHT, bg=\"white\")\n    self.canvas.pack()\n\n    self.button_frame = tk.Frame(self.root)\n    self.button_frame.pack()\n\n    self.predict_btn = tk.Button(\n        self.button_frame, text=\"Predict\", command=self.trigger_send_image\n    )\n    self.predict_btn.pack(side=tk.LEFT, padx=10)\n\n    self.clear_btn = tk.Button(\n        self.button_frame, text=\"Clear\", command=self.clear_canvas\n    )\n    self.clear_btn.pack(side=tk.LEFT)\n\n    self.result_label = tk.Label(self.root, text=\"\", font=(\"Helvetica\", 16))\n    self.result_label.pack()\n\n    self.image = Image.new(\"L\", (WIDTH, HEIGHT), \"white\")\n    self.draw = ImageDraw.Draw(self.image)\n\n    self._lock = threading.Lock()\n    self._latest_request_id = 0\n    self.last_working_index = 0\n\n    self.servers = [\n        \"http://localhost:8080/predictions/mnist\",  # TorchServe\n        \"http://localhost:8000/predict\",  # FastAPI\n    ]\n\n    self.canvas.bind(\"&lt;B1-Motion&gt;\", self.paint)\n</code></pre>"},{"location":"#drawer.PaintApp.clear_canvas","title":"<code>clear_canvas()</code>","text":"<p>Clears the canvas and resets its state.</p> <pre><code>This method deletes all items from the canvas and redraws a white rectangle\nover the entire canvas area to clear it. Additionally, it resets the text\nof the result label to an empty string.\n\nParameters:\n    None\n\nReturns:\n    None\n</code></pre> Source code in <code>drawer.py</code> <pre><code>def clear_canvas(self):\n    \"\"\"\n    Clears the canvas and resets its state.\n\n        This method deletes all items from the canvas and redraws a white rectangle\n        over the entire canvas area to clear it. Additionally, it resets the text\n        of the result label to an empty string.\n\n        Parameters:\n            None\n\n        Returns:\n            None\n    \"\"\"\n    self.canvas.delete(\"all\")\n    self.draw.rectangle([0, 0, WIDTH, HEIGHT], fill=\"white\")\n    self.result_label.config(text=\"\")\n</code></pre>"},{"location":"#drawer.PaintApp.paint","title":"<code>paint(event)</code>","text":"<p>Draws an oval shape on the canvas based on mouse click coordinates.</p> <pre><code>This method is triggered by a mouse event and it creates an oval on\nthe canvas at the location where the mouse is clicked. The oval has a\nfixed size and is filled with a black color.\n\nArgs:\n    event: The mouse event containing the x and y coordinates\n           of the mouse click.\n\nReturns:\n    None\n</code></pre> Source code in <code>drawer.py</code> <pre><code>def paint(self, event):\n    \"\"\"\n    Draws an oval shape on the canvas based on mouse click coordinates.\n\n        This method is triggered by a mouse event and it creates an oval on\n        the canvas at the location where the mouse is clicked. The oval has a\n        fixed size and is filled with a black color.\n\n        Args:\n            event: The mouse event containing the x and y coordinates\n                   of the mouse click.\n\n        Returns:\n            None\n    \"\"\"\n    x1, y1 = (event.x - 8), (event.y - 8)\n    x2, y2 = (event.x + 8), (event.y + 8)\n    self.canvas.create_oval(x1, y1, x2, y2, fill=\"black\", outline=\"black\")\n    self.draw.ellipse([x1, y1, x2, y2], fill=\"black\")\n</code></pre>"},{"location":"#drawer.PaintApp.send_image","title":"<code>send_image(request_id)</code>","text":"<p>Sends a pre-processed image to a server for prediction.</p> <pre><code>This method rescales the image to 28x28 pixels and converts it to grayscale,\ninverts the pixel values, and encodes the image as a base64 string. It then\nsends this encoded image to the preferred server for prediction. In case of\na failure to connect, it retries with a fallback server. The method updates\nthe user interface with the predicted class or an error message accordingly.\n\nArgs:\n    request_id: An identifier for the request, used to track the most\n        recent processing request and update the label correctly.\n\nReturns:\n    None\n</code></pre> Source code in <code>drawer.py</code> <pre><code>def send_image(self, request_id):\n    \"\"\"\n    Sends a pre-processed image to a server for prediction.\n\n        This method rescales the image to 28x28 pixels and converts it to grayscale,\n        inverts the pixel values, and encodes the image as a base64 string. It then\n        sends this encoded image to the preferred server for prediction. In case of\n        a failure to connect, it retries with a fallback server. The method updates\n        the user interface with the predicted class or an error message accordingly.\n\n        Args:\n            request_id: An identifier for the request, used to track the most\n                recent processing request and update the label correctly.\n\n        Returns:\n            None\n    \"\"\"\n    # \u041c\u0430\u0441\u0448\u0442\u0430\u0431\u0438\u0440\u0443\u0435\u043c \u0434\u043e 28x28, \u043a\u0430\u043a MNIST\n    img = self.image.resize((28, 28)).convert(\"L\")\n\n    # \u0418\u043d\u0432\u0435\u0440\u0442\u0438\u0440\u0443\u0435\u043c (\u0431\u0435\u043b\u044b\u0439 -&gt; 0, \u0447\u0435\u0440\u043d\u044b\u0439 -&gt; 255)\n    img = Image.eval(img, lambda x: 255 - x)\n\n    # \u041e\u0442\u043f\u0440\u0430\u0432\u043b\u044f\u0435\u043c \u0432 API\n    buffer = io.BytesIO()\n    img.save(buffer, format=\"PNG\")\n    img_bytes = buffer.getvalue()\n    img_b64 = base64.b64encode(img_bytes).decode(\"utf-8\")\n    payload = {\"image_bytes\": img_b64}\n\n    def update_label(text):\n        self.root.after(0, self.result_label.config, {\"text\": text})\n\n    # Prioritize the last successful server\n    primary = self.servers[self.last_working_index]\n    fallback = self.servers[1 - self.last_working_index]\n\n    for idx, server in enumerate([primary, fallback]):\n        try:\n            response = requests.post(server, json=payload, timeout=3)\n            pred = response.json()\n            if isinstance(pred, dict):\n                pred = pred.get(\"class_id\", pred)\n\n            with self._lock:\n                if request_id == self._latest_request_id:\n                    self.last_working_index = self.servers.index(server)\n                    update_label(f\"Predicted: {pred}\")\n            return\n        except Exception:\n            continue\n\n    with self._lock:\n        if request_id == self._latest_request_id:\n            update_label(\"Error: all servers unreachable.\")\n</code></pre>"},{"location":"#drawer.PaintApp.trigger_send_image","title":"<code>trigger_send_image()</code>","text":"<p>Triggers the sending of an image in a separate thread.</p> <pre><code>This method increments the latest request ID and starts a new thread\nto send an image using the updated request ID. The thread is set as a\ndaemon, meaning it will not prevent the program from exiting.\n\nParameters:\n    None\n\nReturns:\n    None\n</code></pre> Source code in <code>drawer.py</code> <pre><code>def trigger_send_image(self):\n    \"\"\"\n    Triggers the sending of an image in a separate thread.\n\n        This method increments the latest request ID and starts a new thread\n        to send an image using the updated request ID. The thread is set as a\n        daemon, meaning it will not prevent the program from exiting.\n\n        Parameters:\n            None\n\n        Returns:\n            None\n    \"\"\"\n    with self._lock:\n        self._latest_request_id += 1\n        request_id = self._latest_request_id\n\n    thread = threading.Thread(target=self.send_image, args=(request_id,))\n    thread.daemon = True\n    thread.start()\n</code></pre>"},{"location":"#mnist_handler_1","title":"<code>mnist_handler</code>","text":""},{"location":"#mnist_handler.MNISTHandler","title":"<code>MNISTHandler</code>","text":"<p>               Bases: <code>BaseHandler</code></p> <p>A class to handle the MNIST dataset for model inference and preprocessing.</p> <p>This class is designed to manage the workflow of loading a pre-trained model, preprocessing input data, performing inference, and post-processing the output.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>Initializes the model and device for processing.</p> <code>initialize</code> <p>Loads pre-trained weights into the model.</p> <code>preprocess</code> <p>Converts base64-encoded images into grayscale tensors.</p> <code>inference</code> <p>Executes the model on an input tensor to predict class indices.</p> <code>postprocess</code> <p>Returns the inference output without modifications.</p> <p>Attributes:</p> Name Type Description <code>model</code> <p>The convolutional neural network model used for inference, initialized to None.</p> <code>device</code> <p>The computation device (GPU or CPU) determined for processing.</p> <code>transform</code> <p>Transformations defined for preprocessing input images.</p> <p>This class encapsulates all the necessary functionalities to efficiently prepare input data, interact with a model, and obtain predictions while managing GPU or CPU resources effectively.</p> Source code in <code>mnist_handler.py</code> <pre><code>class MNISTHandler(BaseHandler):\n    \"\"\"\n    A class to handle the MNIST dataset for model inference and preprocessing.\n\n    This class is designed to manage the workflow of loading a pre-trained model,\n    preprocessing input data, performing inference, and post-processing the output.\n\n    Methods:\n        __init__(): Initializes the model and device for processing.\n        initialize(ctx): Loads pre-trained weights into the model.\n        preprocess(data): Converts base64-encoded images into grayscale tensors.\n        inference(input_tensor): Executes the model on an input tensor to predict class indices.\n        postprocess(inference_output): Returns the inference output without modifications.\n\n    Attributes:\n        model: The convolutional neural network model used for inference, initialized to None.\n        device: The computation device (GPU or CPU) determined for processing.\n        transform: Transformations defined for preprocessing input images.\n\n    This class encapsulates all the necessary functionalities to efficiently\n    prepare input data, interact with a model, and obtain predictions while\n    managing GPU or CPU resources effectively.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initialize the model and device for processing.\n\n            This method sets up the initial state of the class, including\n            initializing the model to None, determining the computation\n            device (GPU or CPU), and defining a series of image transformations\n            that will be applied to input data.\n\n            Parameters:\n                None\n\n            Returns:\n                None\n        \"\"\"\n        super().__init__()\n        self.model = None\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.transform = transforms.Compose(\n            [\n                transforms.Grayscale(),  # just in case\n                transforms.Resize((28, 28)),\n                transforms.ToTensor(),\n                transforms.Normalize((0.5,), (0.5,)),\n            ]\n        )\n\n    def initialize(self, ctx):\n        \"\"\"\n        Initializes the model by loading pre-trained weights.\n\n            This method loads a pre-trained model from the specified directory and\n            prepares it for evaluation by setting the appropriate device and mode.\n\n            Args:\n                ctx: The context object that contains system properties, including\n                     the path to the model directory.\n\n            Returns:\n                None\n\n            The method uses the following imported methods:\n            - `SimpleCNN`: This class defines a convolutional neural network.\n              It is initialized in this method to create an instance of the model.\n            - `torch.load`: This function is used to load the model weights from a\n              file. In this case, it retrieves weights from the 'mnist_model.pth'\n              file located in the `model_dir`.\n        \"\"\"\n        # Load model\n        properties = ctx.system_properties\n        model_dir = properties.get(\"model_dir\")\n        model_path = f\"{model_dir}/mnist_model.pth\"\n        self.model = SimpleCNN()\n        self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n        self.model.to(self.device)\n        self.model.eval()\n\n    def preprocess(self, data):\n        \"\"\"\n        Preprocesses the input data to extract and transform an image.\n\n            This method retrieves a base64-encoded image from the provided data and\n            converts it into a grayscale tensor suitable for further processing.\n\n            Args:\n                data: A list of dictionaries containing image data. The first dictionary\n                      must include either a \"body\" or \"data\" key, which contains a\n                      base64-encoded representation of the image, or a key \"image_bytes\"\n                      in case of a dictionary structure.\n\n            Returns:\n                A tensor representing the preprocessed grayscale image, ready for\n                input into a machine learning model.\n\n            Raises:\n                ValueError: If the expected base64-encoded image data is not found\n                            in the input `data`.\n        \"\"\"\n        image_b64 = data[0].get(\"body\") or data[0].get(\"data\")\n        if isinstance(image_b64, dict) and \"image_bytes\" in image_b64:\n            image_bytes = base64.b64decode(image_b64[\"image_bytes\"])\n        else:\n            raise ValueError(\"Expected base64-encoded image_bytes in JSON\")\n\n        image = Image.open(io.BytesIO(image_bytes)).convert(\"L\")\n        image = self.transform(image).unsqueeze(0).to(self.device)\n        return image\n\n    def inference(self, input_tensor):\n        \"\"\"\n        Perform inference on the given input tensor using the model.\n\n            This method runs the model to produce output predictions for the\n            given input tensor without tracking gradients. It retrieves and\n            prints the predicted class index with the highest confidence.\n\n            Args:\n                input_tensor: The input tensor to be fed into the model for\n                              inference.\n\n            Returns:\n                A list containing the predicted class index of the input tensor.\n        \"\"\"\n        with torch.no_grad():\n            outputs = self.model(input_tensor)\n            _, predicted = torch.max(outputs, 1)\n            print(predicted.item())\n        return [predicted.item()]\n\n    def postprocess(self, inference_output):\n        \"\"\"\n        Post-processes the inference output.\n\n            This method receives the output from an inference process and returns it without any modifications.\n\n            Args:\n                inference_output: The output generated from the inference process.\n\n            Returns:\n                The unmodified inference output.\n        \"\"\"\n        return inference_output\n</code></pre>"},{"location":"#mnist_handler.MNISTHandler.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the model and device for processing.</p> <pre><code>This method sets up the initial state of the class, including\ninitializing the model to None, determining the computation\ndevice (GPU or CPU), and defining a series of image transformations\nthat will be applied to input data.\n\nParameters:\n    None\n\nReturns:\n    None\n</code></pre> Source code in <code>mnist_handler.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initialize the model and device for processing.\n\n        This method sets up the initial state of the class, including\n        initializing the model to None, determining the computation\n        device (GPU or CPU), and defining a series of image transformations\n        that will be applied to input data.\n\n        Parameters:\n            None\n\n        Returns:\n            None\n    \"\"\"\n    super().__init__()\n    self.model = None\n    self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    self.transform = transforms.Compose(\n        [\n            transforms.Grayscale(),  # just in case\n            transforms.Resize((28, 28)),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5,), (0.5,)),\n        ]\n    )\n</code></pre>"},{"location":"#mnist_handler.MNISTHandler.inference","title":"<code>inference(input_tensor)</code>","text":"<p>Perform inference on the given input tensor using the model.</p> <pre><code>This method runs the model to produce output predictions for the\ngiven input tensor without tracking gradients. It retrieves and\nprints the predicted class index with the highest confidence.\n\nArgs:\n    input_tensor: The input tensor to be fed into the model for\n                  inference.\n\nReturns:\n    A list containing the predicted class index of the input tensor.\n</code></pre> Source code in <code>mnist_handler.py</code> <pre><code>def inference(self, input_tensor):\n    \"\"\"\n    Perform inference on the given input tensor using the model.\n\n        This method runs the model to produce output predictions for the\n        given input tensor without tracking gradients. It retrieves and\n        prints the predicted class index with the highest confidence.\n\n        Args:\n            input_tensor: The input tensor to be fed into the model for\n                          inference.\n\n        Returns:\n            A list containing the predicted class index of the input tensor.\n    \"\"\"\n    with torch.no_grad():\n        outputs = self.model(input_tensor)\n        _, predicted = torch.max(outputs, 1)\n        print(predicted.item())\n    return [predicted.item()]\n</code></pre>"},{"location":"#mnist_handler.MNISTHandler.initialize","title":"<code>initialize(ctx)</code>","text":"<p>Initializes the model by loading pre-trained weights.</p> <pre><code>This method loads a pre-trained model from the specified directory and\nprepares it for evaluation by setting the appropriate device and mode.\n\nArgs:\n    ctx: The context object that contains system properties, including\n         the path to the model directory.\n\nReturns:\n    None\n\nThe method uses the following imported methods:\n- `SimpleCNN`: This class defines a convolutional neural network.\n  It is initialized in this method to create an instance of the model.\n- `torch.load`: This function is used to load the model weights from a\n  file. In this case, it retrieves weights from the 'mnist_model.pth'\n  file located in the `model_dir`.\n</code></pre> Source code in <code>mnist_handler.py</code> <pre><code>def initialize(self, ctx):\n    \"\"\"\n    Initializes the model by loading pre-trained weights.\n\n        This method loads a pre-trained model from the specified directory and\n        prepares it for evaluation by setting the appropriate device and mode.\n\n        Args:\n            ctx: The context object that contains system properties, including\n                 the path to the model directory.\n\n        Returns:\n            None\n\n        The method uses the following imported methods:\n        - `SimpleCNN`: This class defines a convolutional neural network.\n          It is initialized in this method to create an instance of the model.\n        - `torch.load`: This function is used to load the model weights from a\n          file. In this case, it retrieves weights from the 'mnist_model.pth'\n          file located in the `model_dir`.\n    \"\"\"\n    # Load model\n    properties = ctx.system_properties\n    model_dir = properties.get(\"model_dir\")\n    model_path = f\"{model_dir}/mnist_model.pth\"\n    self.model = SimpleCNN()\n    self.model.load_state_dict(torch.load(model_path, map_location=self.device))\n    self.model.to(self.device)\n    self.model.eval()\n</code></pre>"},{"location":"#mnist_handler.MNISTHandler.postprocess","title":"<code>postprocess(inference_output)</code>","text":"<p>Post-processes the inference output.</p> <pre><code>This method receives the output from an inference process and returns it without any modifications.\n\nArgs:\n    inference_output: The output generated from the inference process.\n\nReturns:\n    The unmodified inference output.\n</code></pre> Source code in <code>mnist_handler.py</code> <pre><code>def postprocess(self, inference_output):\n    \"\"\"\n    Post-processes the inference output.\n\n        This method receives the output from an inference process and returns it without any modifications.\n\n        Args:\n            inference_output: The output generated from the inference process.\n\n        Returns:\n            The unmodified inference output.\n    \"\"\"\n    return inference_output\n</code></pre>"},{"location":"#mnist_handler.MNISTHandler.preprocess","title":"<code>preprocess(data)</code>","text":"<p>Preprocesses the input data to extract and transform an image.</p> <pre><code>This method retrieves a base64-encoded image from the provided data and\nconverts it into a grayscale tensor suitable for further processing.\n\nArgs:\n    data: A list of dictionaries containing image data. The first dictionary\n          must include either a \"body\" or \"data\" key, which contains a\n          base64-encoded representation of the image, or a key \"image_bytes\"\n          in case of a dictionary structure.\n\nReturns:\n    A tensor representing the preprocessed grayscale image, ready for\n    input into a machine learning model.\n\nRaises:\n    ValueError: If the expected base64-encoded image data is not found\n                in the input `data`.\n</code></pre> Source code in <code>mnist_handler.py</code> <pre><code>def preprocess(self, data):\n    \"\"\"\n    Preprocesses the input data to extract and transform an image.\n\n        This method retrieves a base64-encoded image from the provided data and\n        converts it into a grayscale tensor suitable for further processing.\n\n        Args:\n            data: A list of dictionaries containing image data. The first dictionary\n                  must include either a \"body\" or \"data\" key, which contains a\n                  base64-encoded representation of the image, or a key \"image_bytes\"\n                  in case of a dictionary structure.\n\n        Returns:\n            A tensor representing the preprocessed grayscale image, ready for\n            input into a machine learning model.\n\n        Raises:\n            ValueError: If the expected base64-encoded image data is not found\n                        in the input `data`.\n    \"\"\"\n    image_b64 = data[0].get(\"body\") or data[0].get(\"data\")\n    if isinstance(image_b64, dict) and \"image_bytes\" in image_b64:\n        image_bytes = base64.b64decode(image_b64[\"image_bytes\"])\n    else:\n        raise ValueError(\"Expected base64-encoded image_bytes in JSON\")\n\n    image = Image.open(io.BytesIO(image_bytes)).convert(\"L\")\n    image = self.transform(image).unsqueeze(0).to(self.device)\n    return image\n</code></pre>"},{"location":"#model_1","title":"<code>model</code>","text":""},{"location":"#model.SimpleCNN","title":"<code>SimpleCNN</code>","text":"<p>               Bases: <code>Module</code></p> <p>A convolutional neural network class for processing input data.</p> <p>This class constructs a convolutional neural network (CNN) that consists of a sequence of layers, including convolutional, activation, pooling, flattening, and fully connected layers, to enable image classification or other tasks.</p> <p>Methods:</p> Name Description <code>__init__</code> <p>Initializes the SimpleCNN class.</p> <code>forward</code> <p>Processes the input through the network.</p> <p>The init method sets up the architecture of the CNN, while the forward method takes the input data, processes it through the layers of the network, and returns the resulting output.</p> Source code in <code>model.py</code> <pre><code>class SimpleCNN(nn.Module):\n    \"\"\"\n    A convolutional neural network class for processing input data.\n\n    This class constructs a convolutional neural network (CNN) that consists of a\n    sequence of layers, including convolutional, activation, pooling, flattening,\n    and fully connected layers, to enable image classification or other tasks.\n\n    Methods:\n        __init__: Initializes the SimpleCNN class.\n        forward: Processes the input through the network.\n\n    Attributes:\n        None\n\n    The __init__ method sets up the architecture of the CNN, while the forward\n    method takes the input data, processes it through the layers of the network,\n    and returns the resulting output.\n    \"\"\"\n\n    def __init__(self):\n        \"\"\"\n        Initializes the SimpleCNN class.\n\n            This method constructs a convolutional neural network using a sequence of\n            layers including convolutional, activation, pooling, flattening, and fully\n            connected layers.\n\n            Parameters:\n                None\n\n            Returns:\n                None\n        \"\"\"\n        super(SimpleCNN, self).__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(1, 16, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Conv2d(16, 32, 3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2),\n            nn.Flatten(),\n            nn.Linear(32 * 7 * 7, 128),\n            nn.ReLU(),\n            nn.Linear(128, 10),\n        )\n\n    def forward(self, x):\n        \"\"\"\n        Processes the input through the network.\n\n            This method feeds the input data into the neural network and returns the output generated by the network.\n\n            Args:\n                x: The input data to be processed by the network.\n\n            Returns:\n                The output of the network after processing the input data.\n        \"\"\"\n        return self.net(x)\n</code></pre>"},{"location":"#model.SimpleCNN.__init__","title":"<code>__init__()</code>","text":"<p>Initializes the SimpleCNN class.</p> <pre><code>This method constructs a convolutional neural network using a sequence of\nlayers including convolutional, activation, pooling, flattening, and fully\nconnected layers.\n\nParameters:\n    None\n\nReturns:\n    None\n</code></pre> Source code in <code>model.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Initializes the SimpleCNN class.\n\n        This method constructs a convolutional neural network using a sequence of\n        layers including convolutional, activation, pooling, flattening, and fully\n        connected layers.\n\n        Parameters:\n            None\n\n        Returns:\n            None\n    \"\"\"\n    super(SimpleCNN, self).__init__()\n    self.net = nn.Sequential(\n        nn.Conv2d(1, 16, 3, padding=1),\n        nn.ReLU(),\n        nn.MaxPool2d(2, 2),\n        nn.Conv2d(16, 32, 3, padding=1),\n        nn.ReLU(),\n        nn.MaxPool2d(2, 2),\n        nn.Flatten(),\n        nn.Linear(32 * 7 * 7, 128),\n        nn.ReLU(),\n        nn.Linear(128, 10),\n    )\n</code></pre>"},{"location":"#model.SimpleCNN.forward","title":"<code>forward(x)</code>","text":"<p>Processes the input through the network.</p> <pre><code>This method feeds the input data into the neural network and returns the output generated by the network.\n\nArgs:\n    x: The input data to be processed by the network.\n\nReturns:\n    The output of the network after processing the input data.\n</code></pre> Source code in <code>model.py</code> <pre><code>def forward(self, x):\n    \"\"\"\n    Processes the input through the network.\n\n        This method feeds the input data into the neural network and returns the output generated by the network.\n\n        Args:\n            x: The input data to be processed by the network.\n\n        Returns:\n            The output of the network after processing the input data.\n    \"\"\"\n    return self.net(x)\n</code></pre>"},{"location":"#server_1","title":"<code>server</code>","text":""},{"location":"#server.ImageRequest","title":"<code>ImageRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A class to handle image requests, encapsulating the functionality related to image data processing and management.</p> <p>Attributes:</p> Name Type Description <code>image_bytes</code> <code>bytes</code> <p>The raw byte data of the image.</p> <p>This class is designed to receive, store, and facilitate operations on image data, providing a simple interface for working with images in byte form.</p> Source code in <code>server.py</code> <pre><code>class ImageRequest(BaseModel):\n    \"\"\"\n    A class to handle image requests, encapsulating the functionality\n    related to image data processing and management.\n\n    Attributes:\n        image_bytes: The raw byte data of the image.\n\n    Methods:\n        None\n\n    This class is designed to receive, store, and facilitate operations\n    on image data, providing a simple interface for working with images\n    in byte form.\n    \"\"\"\n\n    image_bytes: bytes\n</code></pre>"},{"location":"#server.predict","title":"<code>predict(req)</code>  <code>async</code>","text":"<p>Predicts the class of an image based on the input data.</p> <p>This method decodes a base64-encoded image, processes it, and then uses a pre-trained model to predict the class of the image. The prediction is returned as a dictionary containing the class identifier.</p> <p>Parameters:</p> Name Type Description Default <code>req</code> <code>ImageRequest</code> <p>An instance of ImageRequest containing the base64-encoded image data.</p> required <p>Returns:</p> Type Description <p>A dictionary with the predicted class identifier under the key \"class_id\".</p> Source code in <code>server.py</code> <pre><code>@app.post(\"/predict\")\nasync def predict(req: ImageRequest):\n    \"\"\"\n    Predicts the class of an image based on the input data.\n\n    This method decodes a base64-encoded image, processes it, and then uses a\n    pre-trained model to predict the class of the image. The prediction is\n    returned as a dictionary containing the class identifier.\n\n    Args:\n        req: An instance of ImageRequest containing the base64-encoded image data.\n\n    Returns:\n        A dictionary with the predicted class identifier under the key \"class_id\".\n    \"\"\"\n    image_bytes = base64.b64decode(req.image_bytes)\n    image = Image.open(io.BytesIO(image_bytes)).convert(\"RGB\")\n    image = transform(image).unsqueeze(0)\n    outputs = model(image)\n    _, predicted = torch.max(outputs.data, 1)\n    return {\"class_id\": predicted.item()}\n</code></pre>"}]}